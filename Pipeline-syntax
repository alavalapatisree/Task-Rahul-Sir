 A Jenkinsfile can be written using two types of syntax — Declarative and Scripted.
Declarative Pipeline is a more recent feature of Jenkins Pipeline which:
  * Provides richer syntactical features over Scripted Pipeline syntax, and
  * Is designed to make writing and reading Pipeline code easier.

Durable: Pipelines can survive both planned and unplanned restarts of the Jenkins controller, but freestyle job can't.

PIPELINE CONCEPTS ==

Pipeline - pipeline is a set of definitions that allows you to automate the processes of Continuous Integration (CI) and Continuous Delivery (CD).
Node - node represents an environment (often a machine or a container) where the steps of a pipeline can be executed.
Stage - stage is a phase or section of your overall pipeline, and within each stage, you can define multiple "steps."
Step - A single task. Fundamentally, a step tells Jenkins what to do at a particular point in time.


options {
    skipStagesAfterUnstable()
}
-----If any stage is unstable, then the stages after unstable stage is skipped.
(Unstable in jenkins means -  stage is completed but some non-critical issues are detected ---Test failures, Code quality Metrics)

A Pipeline can be created in one of the following ways:

1) Through Blue Ocean - after setting up a Pipeline project in Blue Ocean, the Blue Ocean UI helps you write your Pipeline’s Jenkinsfile and commit it to source control.
2) Through the classic UI - you can enter a basic Pipeline directly in Jenkins through the classic UI.
3) In SCM - you can write a Jenkinsfile manually, which you can commit to your project’s source control repository.

A Jenkinsfile created using the classic UI is stored by Jenkins itself (within the Jenkins home directory).

env -  The env global variable in Jenkins Pipeline provides access to environment variables, allowing you to retrieve information about the environment in which the pipeline is running.
                    def buildId = env.BUILD_ID
                    def jobName = env.JOB_NAME
                    echo "Build ID: ${buildId}, Job Name: ${jobName}"

 params -  the params global variable provides access to all the parameters defined for the pipeline. It exposes these parameters as a read-only map, allowing you to retrieve and use their 
values within your pipeline script.

pipeline {
    agent any

    stages {
        stage('Build') {
            steps {
                echo 'Building..'
            }
        }
        stage('Test') {
            steps {
                echo 'Testing..'
            }
        }
        stage('Deploy') {
            steps {
                echo 'Deploying....'
            }
        }
    }
}

* Jenkinsfile is to be created in root directoy of project.
* Jenkinsfile without an agent directive, it is not capable of doing any work.
* stage diective, steps directive also required for a valid declarative pipeline.

checkout scm
* checkout - this is used to checkout code from source control.
* scm - this is a special variable which instructs the checkout step to clone the specific revision.

Jenkinsfile is not a replacement for an existing build tool such as GNU/Make, Maven, Gradle, etc, but rather can be viewed 
as a glue layer to bind the multiple phases of a project’s development lifecycle (build, test, deploy, etc) together.

pipeline {
    agent any

    stages {
        stage('Build') {
            steps {
                sh 'make'
                archiveArtifacts artifacts: '**/target/*.jar', fingerprint: true
            }
        }
    }
}

* sh 'make'
sh step is used to execute shell commands
sh 'make' means that the Jenkins pipeline will execute the make command
the make command reads a file called Makefile to determine how to build and compile a program. The Makefile contains rules and dependencies that specify how different parts of the program depend on each other and how they should be built.


* archiveArtifacts artifacts: '**/target/*.jar', fingerprint: true
archiveArtifacts: This is a Jenkins Pipeline step used to archive artifacts, making them available for future reference and use.
artifacts: '**/target/*.jar': This specifies the files or patterns of files to be archived.
fingerprint: true: This option is set to true to enable fingerprinting for the archived artifacts. Fingerprinting generates a unique identifier (hash) for each version of the artifact based on its content. 

Archiving artifacts is not a substitute for using external artifact repositories such as Artifactory or Nexus and should be considered only for basic reporting and file archival.

* sh 'make check || true'
make check: Runs the checks or tests specified in the check target of the Makefile.
||: The logical OR operator in shell scripting.
true : A command that always succeeds, used to ensure that the entire command (make test || true) exits successfully, regardless of the success or failure of the make test command.

In the context of a build script, CI/CD pipeline, or any automated build process, it's a common pattern to include || true after a potentially failing command when you want to ensure that the overall process continues, even if a specific step fails.


* junit '**/target/*.xml'
After running your JUnit tests as part of your Jenkins Pipeline, the testing framework likely generates XML files containing detailed information about the test results.
The junit step is a Jenkins Pipeline step specifically designed to process JUnit test results. It takes as an argument a file pattern indicating where to find the JUnit XML files.
The junit step processes the specified JUnit XML files and extracts information about test results.
The results are then displayed in the Jenkins build dashboard, providing a visual representation of which tests passed, which failed, and any additional details about test failures or errors.


*
when {
    expression {
        currentBuild.result == null || currentBuild.result == 'SUCCESS' 
    }
}

when :  It is used to define conditions under which a stage or block should be executed.
expression: This specifies that the condition is expressed using a Groovy expression.
the currentBuild.result variable is used to access the result of the current build. 
currentBuild.result: currentBuild is a built-in variable in Jenkins that represents the current build. The result property of currentBuild represents the result of the current build.
== null || currentBuild.result == 'SUCCESS': This is the Groovy expression defining the condition.
The condition is true (SUCCESS) if the build result is either null (indicating the build is still running) or if the result is 'SUCCESS'.

SUCCESS: The build is considered successful. All stages and tests have passed without any failures or errors.

FAILURE: The build is considered failed. At least one stage or test has failed.

UNSTABLE: The build is considered unstable. This usually indicates that the build was successful, but some tests or quality criteria are not met. 

${YOUR_JENKINS_URL}/pipeline-syntax/globals#env  --- list of environment variables accessible from within Jenkins Pipeline

BUILD_ID
The current build ID, identical to BUILD_NUMBER for builds created in Jenkins versions 1.597+

BUILD_NUMBER
The current build number, such as "153"

BUILD_TAG
String of jenkins-${JOB_NAME}-${BUILD_NUMBER}. Convenient to put into a resource file, a jar file, etc for easier identification

BUILD_URL
The URL where the results of this build can be found (for example http://buildserver/jenkins/job/MyJobName/17/ )

EXECUTOR_NUMBER
The unique number that identifies the current executor (among executors of the same machine) performing this build. This is the number you see in the "build executor status", except that the number starts from 0, not 1

JAVA_HOME
If your job is configured to use a specific JDK, this variable is set to the JAVA_HOME of the specified JDK. When this variable is set, PATH is also updated to include the bin subdirectory of JAVA_HOME

JENKINS_URL
Full URL of Jenkins, such as https://example.com:port/jenkins/ (NOTE: only available if Jenkins URL set in "System Configuration")

JOB_NAME
Name of the project of this build, such as "foo" or "foo/bar".

NODE_NAME
The name of the node the current build is running on. Set to 'master' for the Jenkins controller.

WORKSPACE
The absolute path of the workspace

* echo "Running ${env.BUILD_ID} on ${env.JENKINS_URL}"


pipeline {
    agent any
    environment {
        CC = 'clang'
    }
    stages {
        stage('Example') {
            environment {
                DEBUG_FLAGS = '-g'
            }
            steps {
                sh 'printenv'
            }
        }
    }
}

environment: Defines environment variables for the entire pipeline. In this case, it sets the CC variable to 'clang'.
environment (within 'Example' stage): Defines environment variables specific to the 'Example' stage. It sets the DEBUG_FLAGS variable to '-g'.
sh 'printenv': Executes the shell command printenv, which prints the environment variables. This step is executed within the 'Example' stage. (cc is global so will also print)


An environment directive used in the top-level pipeline block will apply to all steps within the Pipeline.
An environment directive defined within a stage will only apply the given environment variables to steps within the stage.



pipeline {
    agent any
    environment {
        // Using returnStdout
        CC = """${sh(
                returnStdout: true,
                script: 'echo "clang"'
            )}"""
        // Using returnStatus
        EXIT_STATUS = """${sh(
                returnStatus: true,
                script: 'exit 1'
            )}"""
    }
    stages {
        stage('Example') {
            environment {
                DEBUG_FLAGS = '-g'
            }
            steps {
                sh 'printenv'
            }
        }
    }
}

returnStdout:

Captures the standard output of the command.
Useful when you want to capture the output produced by the shell command for further processing or logging.
returnStatus:

Captures the exit status of the command.
Useful when you want to determine whether the shell command succeeded or failed based on its exit status.

An agent must be set at the top level of the pipeline. This will fail if agent is set as agent none.
When using returnStdout a trailing whitespace will be appended to the returned string. Use .trim() to remove this.


Credentials::
Jenkins' declarative Pipeline syntax has the credentials() helper method (used within the environment directive) which supports secret text, username and password, as well as secret file credentials. 

credentials('credential ID')
Secret text:

environment {
        AWS_ACCESS_KEY_ID     = credentials('jenkins-aws-secret-key-id')
        AWS_SECRET_ACCESS_KEY = credentials('jenkins-aws-secret-access-key')
    }

jenkins-aws-secret-key-id, jenkins-aws-secret-access-key these two are 2 different secret texts.

if you try to access like --- echo ' this is my secret text $AWS_ACCESS_KEY_ID'    It can't access  AWS_ACCESS_KEY_ID value.. so we need to prvide it in double quotes " "
echo " this is my secret text $AWS_ACCESS_KEY_ID"

-> To access any variables in echo we need to use "" not ''.
Generally try to see the credential is not secure in pipeline. if we use double quotes for credentials Jenkins only returns the value “****” to reduce the risk of secret information being disclosed to the console output and any logs. 


Username and password:

environment {
    BITBUCKET_COMMON_CREDS = credentials('jenkins-bitbucket-common-creds')
}

this actually sets the following three environment variables:

BITBUCKET_COMMON_CREDS - contains a username and a password separated by a colon in the format username:password.

BITBUCKET_COMMON_CREDS_USR - an additional variable containing the username component only.

BITBUCKET_COMMON_CREDS_PSW - an additional variable containing the password component only.

Secret files:

A secret file is a credential which is stored in a file and uploaded to Jenkins. Secret files are used for credentials that are:

* too unwieldy to enter directly into Jenkins, and/or
* in binary format, such as a GPG file.

SSH User Private Key example:
withCredentials(bindings: [sshUserPrivateKey(credentialsId: 'jenkins-ssh-key-for-abc', \
                                             keyFileVariable: 'SSH_KEY_FOR_ABC', \
                                             passphraseVariable: '', \
                                             usernameVariable: '')]) {
  // some block
}

Certificate example:
withCredentials(bindings: [certificate(aliasVariable: '', \
                                       credentialsId: 'jenkins-certificate-for-xyz', \
                                       keystoreVariable: 'CERTIFICATE_FOR_XYZ', \
                                       passwordVariable: 'XYZ-CERTIFICATE-PASSWORD')]) {
  // some block
}


String interpolation::

def username = 'Jenkins'
echo 'Hello Mr. ${username}'
echo "I said, Hello Mr. ${username}"

Hello Mr. ${username}
I said, Hello Mr. Jenkins


post actions:

pipeline {
    agent any
    stages {
        stage('Test') {
            steps {
                sh 'make check'
            }
        }
    }
    post {
        always {
            junit '**/target/*.xml'
        }
        failure {
            mail to: team@example.com, subject: 'The Pipeline failed :('
        }
    }
}


Using multiple agents:

pipeline {
    agent none
    stages {
        stage('Build') {
            agent any
            steps {
                checkout scm
                sh 'make'
                stash includes: '**/target/*.jar', name: 'app'
            }
        }
        stage('Test on Linux') {
            agent {
                label 'linux'
            }
            steps {
                unstash 'app'
                sh 'make check'
            }
            post {
                always {
                    junit '**/target/*.xml'
                }
            }
        }
        stage('Test on Windows') {
            agent {
                label 'windows'
            }
            steps {
                unstash 'app'
                bat 'make check'
            }
            post {
                always {
                    junit '**/target/*.xml'
                }
            }
        }
    }
}

stash includes: '**/target/*.jar', name: 'app'

stash step in a Jenkins Pipeline is used to archive and stash files for later use
includes: '**/target/*.jar': Specifies the files to include in the stash. 
name: 'app': Specifies a name for the stash. In this case, the stash is named 'app'. 
you can use the unstash step to retrieve and unarchive the files.


Optional step arguments:


git url: 'git://example.com/amazing-project.git', branch: 'master'
git([url: 'git://example.com/amazing-project.git', branch: 'master'])

sh 'echo hello' /* short form  */
sh([script: 'echo hello'])  /* long form */

both ways are correct.. based on situation we can use.

Parallel execution:

pipeline {
    agent any

    stages {
        stage('Parallel Stage') {
            parallel {
                stage('Parallel Stage 1') {
                    steps {
                        echo 'Running Parallel Stage 1'
                    }
                }
                stage('Parallel Stage 2') {
                    steps {
                        echo 'Running Parallel Stage 2'
                    }
                }
                stage('Parallel Stage 3') {
                    steps {
                        echo 'Running Parallel Stage 3'
                    }
                }
            }
        }

        stage('Sequential Stage') {
            steps {
                echo 'Running Sequential Stage'
            }
        }
    }
}

Restart from a Stage:
You can restart any completed Declarative Pipeline from any top-level stage which ran in that Pipeline. 
Once your Pipeline has completed, whether it succeeds or fails, you can go to the side panel for the run in the classic UI and click on "Restart from Stage".
You will be prompted to choose from a list of top-level stages that were executed in the original run, in the order they were executed. 

Once you choose a stage to restart from and click submit, a new build, with a new build number, will be started. All stages before the selected stage will be skipped, and the Pipeline will start executing at the selected stage. From that point on, the Pipeline will run as normal.


options:
1)
options {
    preserveStashes()
}

This configuration is specifying preserveStashes(), which means that stashes from all previous builds of the pipeline will be retained.
The default number of runs to preserve is 1, just the most recent completed build.
2)
options {
    preserveStashes(buildCount: 5)
}

This configuration is specifying preserveStashes(buildCount: 5), which means that stashes from the last 5 builds of the pipeline will be retained.

3)
options {
    timeout(time: 1, unit: 'HOURS')
}

This option sets a timeout for the entire pipeline run. If the pipeline execution exceeds the specified time, Jenkins will automatically abort the pipeline.

4) 
options {
    disableConcurrentBuilds()
}

This option prevents concurrent executions of the same pipeline. If a pipeline is already running, a new run will wait for the current one to finish.


Using Docker with Pipeline ::

pipeline {
    agent {
        docker { image 'node:20.10.0-alpine3.19' }
    }
    stages {
        stage('Test') {
            steps {
                sh 'node --version'
            }
        }
    }
}

When the Pipeline executes, Jenkins will automatically start the specified container and execute the defined steps within.

Workspace synchronization ::
If it is important to keep the workspace synchronized with other stages, use reuseNode true. Otherwise, a dockerized stage can be run on the same agent or any other agent, but in a temporary workspace.

pipeline {
    agent any
    stages {
        stage('Build') {
            agent {
                docker {
                    image 'gradle:8.2.0-jdk17-alpine'
                    // Run the container on the node specified at the
                    // top-level of the Pipeline, in the same workspace,
                    // rather than on a new node entirely:
                    reuseNode true
                }
            }
            steps {
                sh 'gradle --version'
            }
        }
    }
}

Using multiple containers ::

pipeline {
    agent none
    stages {
        stage('Back-end') {
            agent {
                docker { image 'maven:3.9.6-eclipse-temurin-17-alpine' }
            }
            steps {
                sh 'mvn --version'
            }
        }
        stage('Front-end') {
            agent {
                docker { image 'node:20.10.0-alpine3.19' }
            }
            steps {
                sh 'node --version'
            }
        }
    }
}


Using a Dockerfile  ::
For projects requiring a more customized execution environment, Pipeline also supports building and running a container from a Dockerfile in the source repository. 
In contrast to the previous approach of using an "off-the-shelf" container, using the agent { dockerfile true } syntax builds a new image from a Dockerfile, rather than pulling one from Docker Hub.

Dockerfile
FROM node:20.10.0-alpine3.19

RUN apk add -U subversion

pipeline {
    agent { dockerfile true }
    stages {
        stage('Test') {
            steps {
                sh 'node --version'
                sh 'svn --version'
            }
        }
    }
}
